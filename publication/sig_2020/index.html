<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Hongda Jiang">

  
  
  
    
  
  <meta name="description" content="In this paper, we propose an example-driven camera controller which can extract camera behaviors from an example film clip and re-apply the extracted behaviors to a 3D animation, through learning from a collection of camera motions.">

  
  <link rel="alternate" hreflang="en-us" href="/publication/sig_2020/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/publication/sig_2020/">

  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Hongda Jiang">
  <meta property="og:url" content="/publication/sig_2020/">
  <meta property="og:title" content="Example-driven Virtual Cinematography by Learning Camera Behaviors | Hongda Jiang">
  <meta property="og:description" content="In this paper, we propose an example-driven camera controller which can extract camera behaviors from an example film clip and re-apply the extracted behaviors to a 3D animation, through learning from a collection of camera motions."><meta property="og:image" content="/publication/sig_2020/featured.jpg">
  <meta property="twitter:image" content="/publication/sig_2020/featured.jpg"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-05-13T19:11:48&#43;08:00">
    
    <meta property="article:modified_time" content="2020-05-13T19:11:48&#43;08:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/publication/sig_2020/"
  },
  "headline": "Example-driven Virtual Cinematography by Learning Camera Behaviors",
  
  "image": [
    "/publication/sig_2020/featured.jpg"
  ],
  
  "datePublished": "2020-05-13T19:11:48+08:00",
  "dateModified": "2020-05-13T19:11:48+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Hongda Jiang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Hongda Jiang",
    "logo": {
      "@type": "ImageObject",
      "url": "/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "In this paper, we propose an example-driven camera controller which can extract camera behaviors from an example film clip and re-apply the extracted behaviors to a 3D animation, through learning from a collection of camera motions."
}
</script>

  

  


  


  





  <title>Example-driven Virtual Cinematography by Learning Camera Behaviors | Hongda Jiang</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Hongda Jiang</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Hongda Jiang</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Projects</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#accomplishments"><span>Others</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <div class="pub">

  




















  
  
    
  


<div class="article-container pt-3">
  <h1>Example-driven Virtual Cinematography by Learning Camera Behaviors</h1>

  

  


<div class="article-metadata">

  
  
  
  
  <div>
    

  
  <span><a href="/authors/admin/">Hongda Jiang</a></span>, <span><a href="/authors/binwang/">Bin Wang</a></span>, <span><a href="/authors/xiwang/">Xi Wang</a></span>, <span><a href="/authors/marc-christie/">Marc Christie</a></span>, <span><a href="/authors/baoquanchen/">Baoquan Chen</a></span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May 2020
  </span>
  

  

  

  
  
  

  
  

</div>

  













<div class="btn-links mb-3">
  
  








  















  
  
    
  
<a class="btn btn-outline-primary my-1 mr-1" href="https://www.youtube.com/watch?v=QbphVbdiTTk" target="_blank" rel="noopener">
  Video
</a>



<a class="btn btn-outline-primary my-1 mr-1" href="https://doi.org/10.1145/3386569.3392427" target="_blank" rel="noopener">
  DOI
</a>



</div>


</div>


<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style="max-width: 720px; max-height: 291px;">
  <div style="position: relative">
    <img src="/publication/sig_2020/featured_hu4efd7ab37e8f43b51fddee9f9b13dca0_4833963_720x0_resize_q90_lanczos.jpg" alt="" class="featured-image">
    <span class="article-header-caption">We propose the design of a camera motion controller which has the ability to automatically extract camera behaviors from different film clips (on the left) and re-apply these behaviors to a 3D animation (center).</span>
  </div>
</div>



  <div class="article-container">

    
    <h3>Abstract</h3>
    <p class="pub-abstract">Designing a camera motion controller that has the capacity to move a virtual camera automatically in relation with contents of a 3D animation, in a cinematographic and principled way, is a complex and challenging task. Many cinematographic rules exist, yet practice shows there are significant stylistic variations in how these can be applied. In this paper, we propose an example-driven camera controller which can extract camera behaviors from an example film clip and re-apply the extracted behaviors to a 3D animation, through learning from a collection of camera motions.</p>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Type</div>
          <div class="col-12 col-md-9">
            
            
            <a href="/publication/#1">
              Conference paper
            </a>
            
          </div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    
    <div class="row">
      <div class="col-md-1"></div>
      <div class="col-md-10">
        <div class="row">
          <div class="col-12 col-md-3 pub-row-heading">Publication</div>
          <div class="col-12 col-md-9">SIGGRAPH 2020</div>
        </div>
      </div>
      <div class="col-md-1"></div>
    </div>
    <div class="d-md-none space-below"></div>
    

    <div class="space-below"></div>

    <div class="article-style"><h3 id="demo">Demo</h3>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/QbphVbdiTTk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h3 id="method">Method</h3>





  
  











<figure id="figure-our-proposed-framework-for-learning-camera-behaviors-composed-of-a-cinematic-feature-estimator-which-extracts-high-level-features-from-movie-clips-a-gating-network-which-estimates-the-type-of-camera-behavior-from-the-high-level-features-and-a-prediction-network-which-applies-the-estimated-behavior-on-a-3d-animation">


  <a data-fancybox="" href="/publication/sig_2020/overview_hu40d82731d355e574b4f3b96eab833f7d_679487_2000x2000_fit_lanczos_2.png" data-caption="Our proposed framework for learning camera behaviors composed of a Cinematic Feature Estimator which extracts high-level features from movie clips, a Gating network which estimates the type of camera behavior from the high-level features, and a Prediction network which applies the estimated behavior on a 3D animation.">


  <img data-src="/publication/sig_2020/overview_hu40d82731d355e574b4f3b96eab833f7d_679487_2000x2000_fit_lanczos_2.png" class="lazyload" alt="" width="4008" height="1070">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Our proposed framework for learning camera behaviors composed of a Cinematic Feature Estimator which extracts high-level features from movie clips, a Gating network which estimates the type of camera behavior from the high-level features, and a Prediction network which applies the estimated behavior on a 3D animation.
  </figcaption>


</figure>






  
  











<figure id="figure-to-estimate-cinematic-features-from-film-clips-each-frame-should-pass-through-the-following-steps-i-extracting-2d-skeletons-with-lcr-net-ii-pose-association-filling-missing-joints-and-smoothing-and-iii-estimating-features-through-a-neural-network">


  <a data-fancybox="" href="/publication/sig_2020/extractorPipeline_hu54d91a2bab3bb3210b563591de8feb7d_205158_2000x2000_fit_q90_lanczos.jpg" data-caption="To estimate cinematic features from film clips, each frame should pass through the following steps: (i) extracting 2D skeletons with LCR-Net, (ii) pose association, filling missing joints and smoothing, and (iii) estimating features through a neural network.">


  <img data-src="/publication/sig_2020/extractorPipeline_hu54d91a2bab3bb3210b563591de8feb7d_205158_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="3245" height="820">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    To estimate cinematic features from film clips, each frame should pass through the following steps: (i) extracting 2D skeletons with LCR-Net, (ii) pose association, filling missing joints and smoothing, and (iii) estimating features through a neural network.
  </figcaption>


</figure>






  
  











<figure id="figure-learning-stage-of-the-cinematic-feature-estimator-input-data-is-gathered-over-on-a-sliding-window-of-t_c8-frames-to-increase-robustness-during-the-learning-and-testing-phases-the-output-data-gathers-cinematic-features-such-as-the-camera-pose-estimation-in-toric-space-and-character-features">


  <a data-fancybox="" href="/publication/sig_2020/estimation_model_hu38271f885894ebea843bfbaeb0125dc9_322059_2000x2000_fit_q90_lanczos.jpg" data-caption="Learning stage of the Cinematic Feature Estimator. Input data is gathered over on a sliding window of $t_c=8$ frames to increase robustness during the learning and testing phases. The output data gathers cinematic features such as the camera pose estimation in Toric space and character features.">


  <img data-src="/publication/sig_2020/estimation_model_hu38271f885894ebea843bfbaeb0125dc9_322059_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="3852" height="1613">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Learning stage of the Cinematic Feature Estimator. Input data is gathered over on a sliding window of $t_c=8$ frames to increase robustness during the learning and testing phases. The output data gathers cinematic features such as the camera pose estimation in Toric space and character features.
  </figcaption>


</figure>






  
  











<figure id="figure-structure-of-our-mixture-of-experts-moe-training-network-the-network-takes-as-input-the-result-of-the-cinematic-feature-estimator-applied-on-reference-clips-and-the-3d-animation-it-outputs-a-sequence-of-camera-parameters-for-each-frame-of-the-animation-that-can-be-used-to-render-the-animation">


  <a data-fancybox="" href="/publication/sig_2020/gatingPipeline_hua20e9a7b7eced335c41881290619cb5f_720770_2000x2000_fit_q90_lanczos.jpg" data-caption="Structure of our Mixture of Experts (MoE) training network. The network takes as input the result of the Cinematic Feature Estimator applied on reference clips and the 3D animation. It outputs a sequence of camera parameters for each frame of the animation that can be used to render the animation.">


  <img data-src="/publication/sig_2020/gatingPipeline_hua20e9a7b7eced335c41881290619cb5f_720770_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="5943" height="2107">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Structure of our Mixture of Experts (MoE) training network. The network takes as input the result of the Cinematic Feature Estimator applied on reference clips and the 3D animation. It outputs a sequence of camera parameters for each frame of the animation that can be used to render the animation.
  </figcaption>


</figure>






  
  











<figure id="figure-side-track-with-different-main-character-in-side-track-mode-the-camera-will-always-look-from-one-side-of-the-main-character-no-matter-hisher-facing-orientation-green-arrow-indicates-the-main-character-in-each-sequence">


  <a data-fancybox="" href="/publication/sig_2020/sideTrack_hu310ccf28f6def58532f4c27c0170d35a_1081081_2000x2000_fit_q90_lanczos.jpg" data-caption="Side track with different main character. In side track mode, the camera will always look from one side of the main character no matter his/her facing orientation. Green arrow indicates the main character in each sequence.">


  <img data-src="/publication/sig_2020/sideTrack_hu310ccf28f6def58532f4c27c0170d35a_1081081_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="9955" height="2242">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Side track with different main character. In side track mode, the camera will always look from one side of the main character no matter his/her facing orientation. Green arrow indicates the main character in each sequence.
  </figcaption>


</figure>






  
  











<figure id="figure-relative-vs-direct-track-with-same-main-character-relative-track-top-puts-more-emphasis-on-the-male-character-while-the-feeling-conveyed-by-direct-track-bottom-is-more-objective-green-arrow-indicates-the-main-character-in-each-sequence">


  <a data-fancybox="" href="/publication/sig_2020/a_relative_b_direct_hu310ccf28f6def58532f4c27c0170d35a_1268203_2000x2000_fit_q90_lanczos.jpg" data-caption="Relative vs direct track with same main character. Relative track (top) puts more emphasis on the male character; while the feeling conveyed by direct track (bottom) is more objective. Green arrow indicates the main character in each sequence.">


  <img data-src="/publication/sig_2020/a_relative_b_direct_hu310ccf28f6def58532f4c27c0170d35a_1268203_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="9935" height="2221">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Relative vs direct track with same main character. Relative track (top) puts more emphasis on the male character; while the feeling conveyed by direct track (bottom) is more objective. Green arrow indicates the main character in each sequence.
  </figcaption>


</figure>






  
  











<figure id="figure-snapshots-taken-from-two-distinct-camera-motions-computed-on-the-zombie-sequence-using-two-distinct-sequences-of-input-the-green-arrow-represents-the-main-character-as-viewed-in-the-snapshots-there-are-changes-in-the-main-character-throughout-the-sequence-this-enables-the-designer-through-selected-clips-to-emphasize-one-character-over-another-at-different-moments">


  <a data-fancybox="" href="/publication/sig_2020/zombie_seq_overview_hud86d36f5fce07720e2339a00aa120b78_714493_2000x2000_fit_q90_lanczos.jpg" data-caption="Snapshots taken from two distinct camera motions computed on the zombie sequence using two distinct sequences of input. The green arrow represents the main character. As viewed in the snapshots, there are changes in the main character throughout the sequence. This enables the designer, through selected clips, to emphasize one character over another at different moments.">


  <img data-src="/publication/sig_2020/zombie_seq_overview_hud86d36f5fce07720e2339a00aa120b78_714493_2000x2000_fit_q90_lanczos.jpg" class="lazyload" alt="" width="4978" height="2268">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Snapshots taken from two distinct camera motions computed on the zombie sequence using two distinct sequences of input. The green arrow represents the main character. As viewed in the snapshots, there are changes in the main character throughout the sequence. This enables the designer, through selected clips, to emphasize one character over another at different moments.
  </figcaption>


</figure>

<h3 id="bibtex">Bibtex</h3>
<p>TBD</p>
<h3 id="acknowledgement">Acknowledgement</h3>
<p>This work was supported in part by the National Key R&amp;D Program
of China (2018YFB1403900, 2019YFF0302902). We also thank Anthony
Mirabile and Ludovic Burg from University Rennes, Inria,
CNRS, IRISA and Di Zhang from AICFVE, Beijing Film Academy
for their help in animation generation and rendering.</p>
</div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/camera-control/">Camera control</a>
  
  <a class="badge badge-light" href="/tags/animation/">Animation</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/publication/sig_2020/&amp;text=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/publication/sig_2020/&amp;t=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors&amp;body=/publication/sig_2020/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/publication/sig_2020/&amp;title=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors%20/publication/sig_2020/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/publication/sig_2020/&amp;title=Example-driven%20Virtual%20Cinematography%20by%20Learning%20Camera%20Behaviors" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>












  
    
    





  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hua505cabd025b5b71d99d4a2ad09c3c40_15749_270x270_fill_q90_lanczos_center.jpg" alt="Hongda Jiang">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/">Hongda Jiang</a></h5>
      <h6 class="card-subtitle">PhD student of computer graphics</h6>
      <p class="card-text">My research interests include camera control, animation and deep learning.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:jianghd@pku.edu.cn" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/jianghd1996" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    
    





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/binwang/avatar_hu740c0d43af403fdcbf79a2cf3d20b29a_32456_270x270_fill_q90_lanczos_center.jpg" alt="Bin Wang">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/binwang/">Bin Wang</a></h5>
      <h6 class="card-subtitle">Full-time researcher at AICFVE, Beijing Film Academy</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    
    





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/xiwang/avatar_hu52a603635ecebd45650b162dadabb4e5_12861_270x270_fill_q90_lanczos_center.jpg" alt="Xi Wang">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/xiwang/">Xi Wang</a></h5>
      
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:xi.wang@inria.fr" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://triocrossing.github.io/" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    
    





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/marc-christie/avatar_hud45d4de7bbc10f368b94804000535a89_54327_270x270_fill_q90_lanczos_center.jpg" alt="Marc Christie">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/marc-christie/">Marc Christie</a></h5>
      <h6 class="card-subtitle">Professor at University of Rennes 1, Member of the INRIA Mimetic team</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:marc.christie@irisa.fr" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
    
    





  
  
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <img class="avatar mr-3 avatar-circle" src="/authors/baoquanchen/avatar_huc7b9737181d2c74a962b04fb95a0f731_707099_270x270_fill_q90_lanczos_center.jpg" alt="Baoquan Chen">
    

    <div class="media-body">
      <h5 class="card-title"><a href="/authors/baoquanchen/">Baoquan Chen</a></h5>
      <h6 class="card-subtitle">Endowed Boya Professor of Peking University</h6>
      
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:baoquan@pku.edu.cn" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  










  
  



  </div>
</div>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.37431be2d92d7fb0160054761ab79602.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
